This project presents a comparative analysis between Kolmogorov-Arnold Networks (KANs) and Multilayer Perceptrons (MLPs), investigating their theoretical foundations and performance in function approximation tasks. Through experiments involving various mathematical functions and noise conditions, the study demonstrates that KANs achieve comparable accuracy to MLPs while utilizing significantly fewer parameters (e.g., 75 vs. 2751).


[Read the full paper (PDF)](./Paper3.pdf)
